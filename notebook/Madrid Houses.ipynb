{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madrid Houses Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import folium\n",
    "except:\n",
    "    !pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Action Required - Upload the data\n",
    "\n",
    "- Activate the empty cell below (cursor should blink in the empty cell below).\n",
    "- Click the data symbol on the right\n",
    "- Find your data set > Insert to code > Insert pandas DataFrame\n",
    "\n",
    "Make sure to upload & import **madrid_train.csv** and **madrid_test.csv**.\n",
    "\n",
    "For importing **madrid_test.csv**, you should create a new cell by going to `Insert` > `Insert Cell Below`\n",
    "    \n",
    "![as](https://i.imgur.com/mafVWHP.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Action Required - Rename the DataFrame below to the fresly imported df_data_NN\n",
    "\n",
    "Most likely DSX have imported the data as `df_data_5`, `df_data_6` or similar. It is good practive to rename the data in the next cell, and continue from there.\n",
    "\n",
    "* Store the `df_data_X` (where X is a number), from **madrid_train.csv** in `madrid_train`.\n",
    "* Store the `df_data_X` (where X is a number), from **madrid_test.csv** in `madrid_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_train = df_data_5\n",
    "madrid_test = df_data_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Example - Foliem\n",
    "\n",
    "You have the freedom to install packages like Folium. Folium (Leaflet) is a very nice geo data vizualisation tool - Use the !pip install [package] code to install other packages\n",
    "\n",
    "https://folium.readthedocs.io/en/latest/\n",
    "\n",
    "https://github.com/python-visualization/folium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using folium, and the coordinates for Cybele Palace as an indicator for the centre of Madrid, lets look at the density of houses for sale on a map.\n",
    "\n",
    "In less than 10 lines of code, we have in interactive heatmap, showing the popular places where houses are for sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "cybele_palace = (40.418906, -3.692084)\n",
    "\n",
    "lat_lng_list = list( zip( list(madrid_train.lat), list(madrid_train.lng) ) )\n",
    "house_density = [ (lat,lng,0.3) for (lat,lng) in lat_lng_list ]\n",
    "centre_madrid = cybele_palace\n",
    "\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "map_with_houses = folium.Map(centre_madrid, tiles='stamentoner', zoom_start=11)\n",
    "\n",
    "HeatMap(house_density).add_to(map_with_houses)\n",
    "map_with_houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Classic Linear Regression on the size of property to predict the price\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a two data frames. square metre on X, and price on y axis\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "x = madrid_houses[\"mts2\"].to_frame()\n",
    "y = madrid_houses[\"price\"].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplot lib visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x, y)\n",
    "\n",
    "# plot it as in the example at http://scikit-learn.org/\n",
    "plt.figure(figsize=(17, 9))\n",
    "title = \"Linear Regression shows, each square-m is worth {0:.2f} euro\".format( regr.coef_.flatten()[0] )\n",
    "plt.title(title, fontsize=28) \n",
    "plt.scatter(madrid_houses.mts2, madrid_houses.price,  color='black', alpha=0.7)\n",
    "plt.xticks((np.arange(100,2000,100)))\n",
    "plt.yticks((np.arange(20000,10000000,1000000)))\n",
    "plt.xlabel('Area', fontsize=20, color='green')\n",
    "plt.ylabel('Price', fontsize=20, color='green')\n",
    "plt.plot(x, regr.predict(x), color='blue', linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Intercept: \", regr.intercept_)\n",
    "print( \"Cooef: \", regr.coef_)\n",
    "print( \"\")\n",
    "print(\"A house of 100 square m, in Madrid, according to the model will cost about:\" ,regr.predict(100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the model Performance?\n",
    "\n",
    "### For today - a House is well predicted, if the predicted price is less than 10% off from the true price\n",
    "\n",
    "When working for a Data Project, It is good to use metrics the line of business will understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = regr.predict(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = regr.predict(test.mts2.to_frame() )\n",
    "test[\"prediction\"] = prediction_test\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test) == pd.core.frame.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"prediction\" in test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_quite_well_predicted( dataframe_with_predictions ):\n",
    "    \"\"\"\n",
    "        How much houses can we predict well? \n",
    "        \n",
    "        Input: Data frame, with a \"price\" column, and a \"prediction\" column.\n",
    "        \n",
    "        Output: Proportion of houses that are predicted with a MAXIMUM_RELATIVE_ERROR.\n",
    "        \n",
    "        E.g, a output of 0.2, tells us 20% is well predicted.\n",
    "        E.g, a output of 0.99, tells us 99% is well predicted.\n",
    "    \"\"\"\n",
    "    MAXIMUM_RELATIVE_ERROR = 0.1\n",
    "    \n",
    "    assert type(dataframe_with_predictions) == pd.core.frame.DataFrame, \"Please provide a DataFrame as argument...\"\n",
    "    assert \"prediction\" in dataframe_with_predictions.columns, \"Make sure your predictions are in the 'prediction' column...\"\n",
    "    assert \"price\" in dataframe_with_predictions.columns, \"Make sure your the true price is in the 'price' column...\"\n",
    "    \n",
    "    proportion_well_predicted = np.mean( ( np.abs(test.prediction - test.price) ) / test.price < MAXIMUM_RELATIVE_ERROR )\n",
    "    return( proportion_well_predicted )\n",
    "\n",
    "percentage_quite_well_predicted( test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = regr.predict(test.mts2.to_frame() )\n",
    "test[\"prediction\"] = prediction_test\n",
    "\n",
    "\"With a linear model- we are able to predict {0:.2f}% of the houses well!\".format( percentage_quite_well_predicted(test)*100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a modest regression on square-m, will predict with an error rate of 7%.\n",
    "\n",
    "That is, with only the square-m we are able to predict 7% of the houses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with XGBoost - The Kaggle winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid_one_hot_encoded = madrid_with_metro\n",
    "\n",
    "for col in COLUMNS_TO_INDEX_AS_CATEGORIES:\n",
    "    if col in madrid_one_hot_encoded.columns:\n",
    "        temp_res = pd.get_dummies(  madrid_one_hot_encoded[ col ], prefix=col )\n",
    "        madrid_one_hot_encoded[ temp_res.columns ] = temp_res\n",
    "        madrid_one_hot_encoded = madrid_one_hot_encoded.drop(col, 1)\n",
    "\n",
    "madrid_one_hot_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have a wider data set !\n",
    "for col in madrid_one_hot_encoded.columns[1:]:\n",
    "    print( col, end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not interested in all columns, so just take first 40 columns and rooms, bathrooms and mts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_FOR_MODEL = list(madrid_one_hot_encoded.columns[40:]) + [\"rooms\", \"bathrooms\",\"mts2\"]\n",
    "\n",
    "for feature in FEATURE_FOR_MODEL:\n",
    "    print(feature, end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering is just as important (or more), as creating a good model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally, change the CODE below to select features for the model to use - Normally, you would select all protential features\n",
    "\n",
    "If you would like to use all district features, like\n",
    "\n",
    "**district_Arganzuela, district_Barajas, district_Carabanchel, district_Centro, district_Chamartín, district_Chamberí, district_Ciudad Lineal, district_Fuencarral, district_Hortaleza, district_Latina, district_Moncloa, district_Moratalaz, district_Puente de Vallecas, district_Retiro, district_Salamanca, district_San Blas, district_Tetuán, district_Usera, district_Vicálvaro, district_Villa de Vallecas, district_Villaverde**\n",
    "\n",
    "simply enter **`district`**, and the code will add all features containing the work district. Similar for property state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Edit the line below to change the features used by the model.\n",
    "   \n",
    "   FEATURE_SELECTION = FEATURE_FOR_MODEL will use ALL features\n",
    "   \n",
    "\"\"\"\n",
    "SELECTED_BY_USED_FEATURES = [\"distance_to_centre\", \"property_state\", \"district\", \"mts2\", \"sauna\"]\n",
    "\n",
    "FEATURE_SELECTION = []\n",
    "\n",
    "for feature in SELECTED_BY_USED_FEATURES:\n",
    "    for potential_feature in FEATURE_FOR_MODEL:\n",
    "        if feature in potential_feature:\n",
    "            FEATURE_SELECTION.append(potential_feature)\n",
    "            \n",
    "for feat in FEATURE_SELECTION:\n",
    "    print(feat, end=\", \")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test / Train set creation\n",
    "\n",
    "As a data scientist, if there is anough data, I will split my data into Training, Validation and Testing sets in order to tune my model.\n",
    "Tuning (by adding features such as metro), and by configuring the algorithms to go into more levels of depth. \n",
    "\n",
    "In this example we are doing a two way split using 80:20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweak Model parameters to get an even better performance\n",
    "\n",
    "## Can it be good to tweak number of trees, or tree complexity ?\n",
    "\n",
    "![](http://www.iis.ee.ic.ac.uk/icvl/iccv09_tutorial_files/random_forest_new2.png)\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "Having split the data, this next step uses RandomForestRegressor to make predictions. The random forest regressor will only ever predict values within the range of observations or closer to zero. \n",
    "We will run this against the training set, looking at price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SELECTION = [\"distance_to_centre\", \"mts2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\"\"\"\n",
    "    Change the code below, to make the model perform better, and use all information from data as best as possible\n",
    "\"\"\"\n",
    "clf = RandomForestRegressor(max_depth=25, n_estimators=5)\n",
    "\n",
    "target_t = train[ \"price\" ]\n",
    "features_t = train[ FEATURE_SELECTION ]\n",
    "\n",
    "clf.fit(  features_t, target_t )\n",
    "\n",
    "features_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cell attempts to identify features which influence the property price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_dict = {}\n",
    "importance_list = []\n",
    "for (imp, label) in list( zip( list(clf.feature_importances_), FEATURE_SELECTION ) ):\n",
    "    feature_imp_dict[label] = imp\n",
    "    importance_list.append(imp)\n",
    "\n",
    "treshold = sorted(importance_list)[-2] \n",
    "important_features = {}\n",
    "\n",
    "for key in feature_imp_dict:\n",
    "    if feature_imp_dict[key] >= treshold:\n",
    "        important_features[key] = feature_imp_dict[key]\n",
    "        \n",
    "for k,v in sorted(important_features.items(), key=lambda x:-x[1]):\n",
    "    print(k, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we see that the sq.metre is the largest indicator of price, with distance to city centre.\n",
    "\n",
    "Now lets plot this importance of these features...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dictionary = plt.figure()\n",
    "dictionary.set_size_inches(35, 10.5)\n",
    "\n",
    "D = important_features\n",
    "\n",
    "keys = [ s[:20] for s in D.keys()]\n",
    "\n",
    "plt.bar(range(len(D)), D.values(), align='center')\n",
    "plt.xticks(fontsize=14)  \n",
    "plt.xticks(range(len(D)), keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on our training set **mts2** (metre.sq), **distance_to_centre** are important features.\n",
    "\n",
    "## Test model performance on Test set (unseen during model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test[ FEATURE_SELECTION ])\n",
    "\n",
    "test[\"prediction\"] = preds\n",
    "\n",
    "\n",
    "print(\"{0:.2f}% is well predicted\".format(100 * percentage_quite_well_predicted(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using more colorful features, and a more advanced more, we boosted our performance from around 7, to 20%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
