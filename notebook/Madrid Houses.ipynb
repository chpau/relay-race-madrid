{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madrid Houses Hackathon - Predict house prices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Python environment supports pip install\n",
    "\n",
    "Feel free to use additional packages like `geopy` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import folium\n",
    "except:\n",
    "    !pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (!) Action Required - Upload the data\n",
    "\n",
    "- Activate the empty cell below (cursor should blink in the empty cell below).\n",
    "- Click the data symbol on the right\n",
    "- Find your data set > Insert to code > Insert pandas DataFrame\n",
    "\n",
    "Make sure to upload & insert **madrid_train.csv** and **madrid_test.csv**. \n",
    "For importing **madrid_test.csv**, you should create a new cell by going to `Insert` > `Insert Cell Below`. \n",
    "    \n",
    "![as](https://i.imgur.com/mafVWHP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (!) Action Required - Rename the DataFrame below to the fresly imported df_data_NN\n",
    "\n",
    "Most likely DSX have imported the data as `df_data_5`, `df_data_6` or similar. It is good practive to rename the data in the next cell, and continue from there.\n",
    "\n",
    "* Store the `df_data_X` (where X is a number), from **madrid_train.csv** in `madrid_train`.\n",
    "* Store the `df_data_X` (where X is a number), from **madrid_test.csv** in `madrid_test`.\n",
    "\n",
    "Depending on the numbering, it will look like\n",
    "```\n",
    "madrid_train = df_data_1\n",
    "madrid_test = df_data_2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "madrid_train = df_data_3\n",
    "madrid_test = df_data_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Pandas Profiling on Test Set\n",
    "\n",
    "https://github.com/pandas-profiling/pandas-profiling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(madrid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Example - Folium\n",
    "\n",
    "You have the freedom to install packages like Folium. Folium (Leaflet) is a very nice geo data vizualisation tool - Use the !pip install [package] code to install other packages\n",
    "\n",
    "https://folium.readthedocs.io/en/latest/\n",
    "\n",
    "https://github.com/python-visualization/folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "cybele_palace = (40.418906, -3.692084)\n",
    "\n",
    "lat_lng_list = list( zip( list(madrid_train.lat), list(madrid_train.lng) ) )\n",
    "house_density = [ (lat,lng,0.3) for (lat,lng) in lat_lng_list ]\n",
    "centre_madrid = cybele_palace\n",
    "\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "map_with_houses = folium.Map(centre_madrid, tiles='stamentoner', zoom_start=11)\n",
    "\n",
    "HeatMap(house_density).add_to(map_with_houses)\n",
    "map_with_houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Classic Linear Regression on the size of property to predict the price\n",
    "\n",
    "The textbook example on real housing data! How cool.\n",
    "\n",
    "Don't underestimate the Linear Model. Last hackathon on Amsterdam house prices one team for a very sharp result by using a Linear Model, with some very smart features. \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build a two data frames. square metre on X, and price on y axis\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "x = madrid_train[\"mts2\"].to_frame()\n",
    "y = madrid_train[\"price\"].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplot lib visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x, y)\n",
    "\n",
    "# plot it as in the example at http://scikit-learn.org/\n",
    "plt.figure(figsize=(17, 9))\n",
    "title = \"Linear Regression shows, each square-m is worth {0:.2f} euro\".format( regr.coef_.flatten()[0] )\n",
    "plt.title(title, fontsize=28) \n",
    "plt.scatter(madrid_train.mts2, madrid_train.price,  color='black', alpha=0.7)\n",
    "plt.xticks((np.arange(100,2000,100)))\n",
    "plt.yticks((np.arange(20000,10000000,1000000)))\n",
    "plt.xlabel('Area', fontsize=20, color='green')\n",
    "plt.ylabel('Price', fontsize=20, color='green')\n",
    "plt.plot(x, regr.predict(x), color='blue', linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( \"Intercept: \", regr.intercept_)\n",
    "print( \"Cooef: \", regr.coef_)\n",
    "print( \"\")\n",
    "print(\"A house of 100 square m, in Madrid, according to the model will cost about:\" ,regr.predict(100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the model Performance ?\n",
    "\n",
    "### For today - a House is well predicted, if the predicted price is less than 10% off from the true price\n",
    "\n",
    "To test this, we extend the pandas dataframe with a column 'prediction'. The function `percentage_quite_well_predicted()` will later return the model performance. \n",
    "\n",
    "For your own model, repeat those steps to find your model performance;\n",
    "\n",
    "1. Create a new dataframe  from `madrid_test`, and extend it with your predictions in a new column `predictions`\n",
    "2. Call `percentage_quite_well_predicted()` on the newly create test dataframe\n",
    "\n",
    "Example for the Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = regr.predict(x)\n",
    "\n",
    "test = madrid_test.copy()\n",
    "\n",
    "prediction_test = regr.predict(test.mts2.to_frame() )\n",
    "test[\"prediction\"] = prediction_test\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def percentage_quite_well_predicted( dataframe_with_predictions ):\n",
    "    \"\"\"\n",
    "        How much houses can we predict well? \n",
    "        \n",
    "        Input: Data frame, with a \"price\" column, and a \"prediction\" column.\n",
    "        \n",
    "        Output: Proportion of houses that are predicted with a MAXIMUM_RELATIVE_ERROR.\n",
    "        \n",
    "        E.g, a output of 0.2, tells us 20% is well predicted.\n",
    "        E.g, a output of 0.99, tells us 99% is well predicted.\n",
    "    \"\"\"\n",
    "    MAXIMUM_RELATIVE_ERROR = 0.1\n",
    "    \n",
    "    assert type(dataframe_with_predictions) == pd.core.frame.DataFrame, \"Please provide a DataFrame as argument...\"\n",
    "    assert \"prediction\" in dataframe_with_predictions.columns, \"Make sure your predictions are in the 'prediction' column...\"\n",
    "    assert \"price\" in dataframe_with_predictions.columns, \"Make sure your the true price is in the 'price' column...\"\n",
    "    \n",
    "    proportion_well_predicted = np.mean( ( np.abs(test.prediction - test.price) ) / test.price < MAXIMUM_RELATIVE_ERROR )\n",
    "    return( proportion_well_predicted )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "percentage_quite_well_predicted( test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction_test = regr.predict(test.mts2.to_frame() )\n",
    "test[\"prediction\"] = prediction_test\n",
    "\n",
    "\"With a linear model- we are able to predict {0:.2f}% of the houses well!\".format( percentage_quite_well_predicted(test)*100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with Random Forest\n",
    "\n",
    "---\n",
    "\n",
    "The following code will one-hot-encode the columns in `COLUMNS_TO_INDEX_AS_CATEGORIES`, and add them to the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "COLUMNS_TO_INDEX_AS_CATEGORIES = [\"property\", \"property_state\", \"district\"]\n",
    "\n",
    "madrid_one_hot_encoded = madrid_train\n",
    "madrid_one_hot_encoded_test = madrid_test\n",
    "\n",
    "for col in COLUMNS_TO_INDEX_AS_CATEGORIES:\n",
    "    if col in madrid_one_hot_encoded.columns:\n",
    "        temp_res = pd.get_dummies(  madrid_one_hot_encoded[ col ], prefix=col )\n",
    "        madrid_one_hot_encoded[ temp_res.columns ] = temp_res\n",
    "        madrid_one_hot_encoded = madrid_one_hot_encoded.drop(col, 1)\n",
    "        \n",
    "        temp_res = pd.get_dummies(  madrid_one_hot_encoded_test[ col ], prefix=col )\n",
    "        madrid_one_hot_encoded_test[ temp_res.columns ] = temp_res\n",
    "        madrid_one_hot_encoded_test = madrid_one_hot_encoded_test.drop(col, 1)\n",
    "        \n",
    "madrid_one_hot_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying all new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in madrid_one_hot_encoded.columns[1:]:\n",
    "    print( col, end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection - example code (note recommendation for good model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   Edit the line below to change the features used by the model.\n",
    "   \n",
    "   FEATURE_SELECTION = list(madrid_one_hot_encoded.columns)\n",
    "   \n",
    "   will use ALL features\n",
    "   \n",
    "\"\"\"\n",
    "SELECTED_FEATURE_KEYWORDS = [\"property_state\", \"district\", \"mts2\", \"sauna\"]\n",
    "\n",
    "FEATURE_SELECTION = []\n",
    "\n",
    "for feature in SELECTED_FEATURE_KEYWORDS:\n",
    "    for potential_feature in list(madrid_one_hot_encoded.columns):\n",
    "        if feature in potential_feature:\n",
    "            FEATURE_SELECTION.append(potential_feature)\n",
    "            \n",
    "for feat in FEATURE_SELECTION:\n",
    "    print(feat, end=\", \")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test / Train set creation\n",
    "\n",
    "To not over-use the true test set, we are going to re-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(madrid_one_hot_encoded)) < 0.8\n",
    "\n",
    "train = madrid_one_hot_encoded[msk]\n",
    "test = madrid_one_hot_encoded[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\"\"\"\n",
    "    Change the code below, to make the model perform better, and use all information from data as best as possible\n",
    "\"\"\"\n",
    "clf = RandomForestRegressor(max_depth=8, n_estimators=5)\n",
    "\n",
    "target_t = train[ \"price\" ]\n",
    "features_t = train[ FEATURE_SELECTION ]\n",
    "\n",
    "clf.fit(  features_t, target_t )\n",
    "\n",
    "features_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Extractions\n",
    "\n",
    "By the time of writing the code, there was no celan/easy way to get this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_imp_dict = {}\n",
    "importance_list = []\n",
    "for (imp, label) in list( zip( list(clf.feature_importances_), FEATURE_SELECTION ) ):\n",
    "    feature_imp_dict[label] = imp\n",
    "    importance_list.append(imp)\n",
    "\n",
    "treshold = sorted(importance_list)[-2] \n",
    "important_features = {}\n",
    "\n",
    "for key in feature_imp_dict:\n",
    "    if feature_imp_dict[key] >= treshold:\n",
    "        important_features[key] = feature_imp_dict[key]\n",
    "        \n",
    "for k,v in sorted(important_features.items(), key=lambda x:-x[1]):\n",
    "    print(k, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dictionary = plt.figure()\n",
    "dictionary.set_size_inches(35, 10.5)\n",
    "\n",
    "D = important_features\n",
    "\n",
    "keys = [ s[:20] for s in D.keys()]\n",
    "\n",
    "plt.bar(range(len(D)), D.values(), align='center')\n",
    "plt.xticks(fontsize=14)  \n",
    "plt.xticks(range(len(D)), keys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model performance on Test set (unseen during model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = madrid_one_hot_encoded_test.copy()\n",
    "\n",
    "\n",
    "preds = clf.predict(test[ FEATURE_SELECTION ])\n",
    "test[\"prediction\"] = preds\n",
    "\n",
    "\n",
    "print(\"{0:.2f}% is well predicted\".format(100 * percentage_quite_well_predicted(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your own model - or extend one of the 2 example below to boost the performance \n",
    "\n",
    "- Make sure to use  `percentage_quite_well_predicted()` to measure your performance.\n",
    "- **Each team member** should understand and be able to explain the end result (data transformation / model / parameters )\n",
    "- Feel free to use R. The `percentage_quite_well_predicted()` have to be rewritten but is very straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
