{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HACKATHON - Goal: Create a Market Model for the price of a property in Amsterdam\n",
    "\n",
    "Read the instruction and try create a sharp model within your team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import folium\n",
    "except:\n",
    "    !pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (!) Action Required - Importing the data\n",
    "\n",
    "![as](https://i.imgur.com/vo4XluQ.png)\n",
    "\n",
    "- Activate the empty cell below (cursor should blink in the empty cell below).\n",
    "- Click the data symbol on the right\n",
    "- Find your data set > Insert to code > Insert pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (!) Action Required - Rename houses_raw to the fresly imported data frame\n",
    "\n",
    "Most likely DSX have imported the data as `df_data_5` or similar.\n",
    "It is good practive to rename the data in the next cell, and continue from there.\n",
    "\n",
    "* Store the `df_data_X` (where X is a number) `houses_raw` to make the next cells work, indepentenly how name was chosen during import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_raw = df_data_4\n",
    "houses_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Data - As the data is from internet, it might contain faulthy rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterd_on_price = houses_raw[ houses_raw[\"price\"] > 50000 ]\n",
    "filtered_on_type = filterd_on_price[ filterd_on_price[\"type\"] != \"garage\" ]\n",
    "filtered_on_area = filtered_on_type[filtered_on_type[\"area\"] > 10 ]\n",
    "houses = filtered_on_area\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "lat_lng_list = list( zip( list(houses.lat), list(houses.lng) ) )\n",
    "house_density = [ (lat,lng,0.3) for (lat,lng) in lat_lng_list ]\n",
    "centre_amsterdam = (52.372842, 4.893643)\n",
    "\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "map_with_houses = folium.Map(centre_amsterdam, tiles='stamentoner', zoom_start=11)\n",
    "\n",
    "HeatMap(house_density).add_to(map_with_houses)\n",
    "map_with_houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import great_circle\n",
    "\n",
    "def distance_to_Dam_Square(lat, lng):\n",
    "    DAM_SQUARE = (52.372842, 4.893643)\n",
    "    return( great_circle( (lat,lng), DAM_SQUARE ).km )\n",
    "\n",
    "anna_frank = (52.375239, 4.883885)\n",
    "willems_huis = (51.957744, 4.553619)\n",
    "\n",
    "print( \"The distance (KM) from The Anna Frank house, to the Dam Square is \", distance_to_Dam_Square(*anna_frank) )\n",
    "print( \"The distance (KM) from my house, to the Dam Square is \", distance_to_Dam_Square(*willems_huis) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "distance_series = houses.apply( lambda x : distance_to_Dam_Square(x.lat , x.lng) , axis=1)\n",
    "distance_df = distance_series.to_frame(name=\"distance_to_dam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_with_distance = houses.join( distance_df )\n",
    "houses_with_distance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumne_per_square = houses_with_distance.apply( lambda x : (x.volume / (x.area + 1) ) , axis=1)\n",
    "volumne_per_square_df = volumne_per_square.to_frame(name=\"volume_per_square\")\n",
    "volumne_per_square_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_feature_engineered = houses_with_distance.join(volumne_per_square_df)\n",
    "houses_feature_engineered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def house_category( house_type ):\n",
    "    type = 0\n",
    "    \n",
    "    if isinstance( house_type , int):\n",
    "        return( house_type )\n",
    "    \n",
    "    house_type = str(house_type)\n",
    "    if house_type == \"woonhuis\":\n",
    "        return 1\n",
    "    if house_type == \"appartement\":\n",
    "        return 2\n",
    "    if house_type == \"parkeergelegenheid\":\n",
    "        return 3\n",
    "    return type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_feature_engineered[\"type\"] = houses_feature_engineered[\"type\"].apply( house_category )\n",
    "houses_feature_engineered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Test/Train set - Using a seed to make sure nobody has an advantage by randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2018)\n",
    "train_mask = np.random.uniform(size=len(houses_feature_engineered)) <= .85\n",
    "\n",
    "\n",
    "train = houses_feature_engineered[train_mask]\n",
    "test = houses_feature_engineered[~train_mask]\n",
    "\n",
    "print(\"There are {} rows in the train set, There are {} rows in the test set\".format( train.shape[0], test.shape[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - A Classic Linear Regression from a Text-Book, price based on square-m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Create linear regression object\n",
    "regr = LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train[ [\"area\"] ]\n",
    "target = train[ [\"price\"] ]\n",
    "\n",
    "regr.fit( features, target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(features.values, target.values,  color='black')\n",
    "plt.plot(features, regr.predict(features), color='blue',         linewidth=1)\n",
    "plt.xlabel( \"Living Area in Square Meter\")\n",
    "plt.ylabel(\" Price in Euros\")\n",
    "plt.ticklabel_format(style='plain', axis='y', )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Something is 'Quite well Predicted' if the prediction error is 10% or less. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def percentage_quite_well_predicted( actual_values, predicted_values ):\n",
    "    \"\"\"\n",
    "        Summary:\n",
    "            Calculated a performance metrics - understandable for none-analysts,\n",
    "            the number of well predicted prices, which is within an\n",
    "            error margin of 10% (treshold = 0.1)\n",
    "         \n",
    "        Input:\n",
    "            - first argument: A list or numpy array with the actual price \n",
    "            - second argument: A list or numpy array with predictions\n",
    "        \n",
    "        Output:\n",
    "            A single float, indicating the proportion of correctly predicted values\n",
    "            \n",
    "            Example:\n",
    "            0.5 - 50% of predictions are well predicted\n",
    "            0.9 - 90% of predictoins are well predicted\n",
    "\n",
    "    \"\"\"\n",
    "    actual_values = np.array(actual_values ).ravel()\n",
    "    predicted_values = np.array(predicted_values).ravel()\n",
    "    difference = (actual_values - predicted_values) \n",
    "    relative_error = np.absolute(difference) / actual_values\n",
    "    treshold = 0.1\n",
    "    proportion_within_treshold = np.mean( relative_error <= treshold)\n",
    "    return( proportion_within_treshold )\n",
    "\n",
    "\n",
    "# Example call\n",
    "percentage_quite_well_predicted( [100,100,100,100,100], [104,104.4,105.5,79,198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test[ [\"area\"] ]\n",
    "test_target = test[ [\"price\"] ]\n",
    "\n",
    "preds = regr.predict(test_features)\n",
    "\n",
    "probability_correct = percentage_quite_well_predicted(test_target.price.tolist(),  [ val[0] for val in preds]  )\n",
    "\"The model was able to predict {percentage:4.2f}% of the Houses quite well\".format(percentage=(100* probability_correct) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal - Create a (better) model, Trained on the \"train\" set\n",
    "\n",
    "Use the `test` pandas dataframe, and the `percentage_quite_well_predicted()` metric, to calculate the performance of your team\n",
    "\n",
    "\n",
    "To give you a (poor) starting point, XGBOOST have been setup to work on the data. The paremeters are not chosen well.\n",
    "Random Forests, and Neirest Neighbor, has proven to be powerfull models on this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_feature_engineered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[ ['area', 'volume', 'floors', 'year_build', 'has_garden', 'type', 'photos', 'rooms', 'distance_to_dam', 'volume_per_square'] ]\n",
    "y = train[ [\"price\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('scaler', StandardScaler()), ('regressor', XGBRegressor(n_estimators=10, learning_rate=0.9))])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_of_columns = ['area', 'volume', 'floors', 'year_build', 'has_garden', 'type', 'photos', 'rooms', 'distance_to_dam', 'volume_per_square']\n",
    "xgbooster_of_fit = pipeline.steps[1][1].booster()\n",
    "feature_scores = xgbooster_of_fit.get_fscore()\n",
    "labels,feat_importance = zip(*[ (labels_of_columns[int(k[1:])],imp) for (k,imp) in feature_scores.items() ])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "y_ticks = np.array(range(len(feat_importance)))\n",
    "width=.8\n",
    "\n",
    "ax.barh(y_ticks, feat_importance, color=\"blue\")\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_yticks(y_ticks + width / 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_on_test = pipeline.predict(test[['area', 'volume', 'floors', 'year_build', 'has_garden', 'type', 'photos', 'rooms', 'distance_to_dam', 'volume_per_square']])\n",
    "true_values_test = test[[\"price\"]].values\n",
    "\n",
    "\n",
    "probability_correct = percentage_quite_well_predicted(predictions_on_test, true_values_test)\n",
    "\"The model was able to predict {percentage:4.2f}% of the Houses quite well\".format(percentage=(100* probability_correct) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
